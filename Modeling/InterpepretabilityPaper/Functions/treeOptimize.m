function [trainedClassifier] = treeOptimize(trainingData,cvp,Options)
% [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% Returns a trained classifier and its accuracy. This code recreates the
% classification model trained in Classification Learner app. Use the
% generated code to automate training the same model with new data, or to
% learn how to programmatically train models.
%
%  Input:
%      trainingData: A table containing the same predictor and response
%       columns as those imported into the app.
%
%  Output:
%      trainedClassifier: A struct containing the trained classifier. The
%       struct contains various fields with information about the trained
%       classifier.
%
%      trainedClassifier.predictFcn: A function to make predictions on new
%       data.
%
%      validationAccuracy: A double containing the accuracy in percent. In
%       the app, the History list displays this overall accuracy score for
%       each model.
%
% Use the code to train the model with new data. To retrain your
% classifier, call the function from the command line with your original
% data or new data as the input argument trainingData.
%
% For example, to retrain a classifier trained with the original data set
% T, enter:
%   [trainedClassifier, validationAccuracy] = trainClassifier(T)
%
% To make predictions with the returned 'trainedClassifier' on new data T2,
% use
%   yfit = trainedClassifier.predictFcn(T2)
%
% T2 must be a table containing at least the same predictor columns as used
% during training. For details, enter:
%   trainedClassifier.HowToPredict

% Auto-generated by MATLAB on 20-Aug-2020 21:24:05


% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
inputTable = trainingData;
predictorNames = {'BAL002', 'BAL014', 'BAL015', 'BAS002', 'BBI001', ... %1
    'BCH004', 'BCH014', 'BCO017', 'BCP002', 'BER002', ...               %2
    'BFE006', 'BFO000', 'BFO002', 'BGL003', 'BGT001', ...               %3
    'BHD000', 'BHE000', 'BHE001', 'BHE030', 'BIJ001', ...               %4
    'BIN000', 'BKA000', 'BLD004', 'BLE001', 'BMA002', ...               %5
    'BMC000', 'BMC002', 'BNA001', 'BPA016', 'BPR012', ...               %6
    'BTR003', 'BTR006', 'BTS003', 'BUR002', 'BCA006b', ...              %7
    'ASAT_ALAT', 'BKR000b', 'qID130460', 'qID130461', 'qID130462', ...  %8
    'qID130464', 'qID130465', 'Systolic', 'Diastolic', ... %9
    'vID120883', 'Age', 'rokenpy', 'hypmedn', 'insuleh', ...            %10
    'Height', 'WeightMax', 'BMImax', 'WCmax', 'BRImax', ...             %11
    'ABSImax', 'TBFMmax', 'WeightMin', 'BMImin', 'WCmin', ...           %12
    'Comorb_Score', 'EtOH_Score', 'QoL_score', 'BARO_score', 'Rand36_score', ...
    'BRImin', 'ABSImin', 'TBFMmin'};                                    %14
predictors = inputTable(:, predictorNames);
response = inputTable.TWL;
isCategoricalPredictor = [false, false, false, false, false, ...        %1
    false, false, false, false, false, ...                              %2
    false, false, false, false, false, ...                              %3 
    false, false, false, false, false, ...                              %4
    false, false, false, false, false, ...                              %5
    false, false, false, false, false, ...                              %6
    false, false, false, false, false, ...                              %7
    false, false, false, false, false, ...                              %8
    false, false, false, false,  ...                              %9
    true,  false, false, false, false, ...                              %10
    false, false, false, false, false, ...                              %11
    false, false, false, false, false, ...                              %12
    false, false, false, false, false, ...                              %13
    false, false, false];                                               %14

% Train a classifier
% This code specifies all the classifier options and trains the classifier.
classificationTree = fitctree(...
    predictors, ...
    response, ...
    'SplitCriterion', 'gdi', ...
    'OptimizeHyperparameters', {'MinLeafSize','MaxNumSplits'}, ...
    'Surrogate', 'on', ...
    'Cost', [0 Options.Cost_FP; Options.Cost_FN 0], ...
    'ClassNames', [0; 1], ...
    'Prior', 'empirical', ...
    'PredictorNames', predictorNames, ...
    'ResponseName', Options.metric, ...
    'AlgorithmForCategorical', 'Exact', ...
    'CategoricalPredictors', isCategoricalPredictor, ...
    'HyperparameterOptimizationOptions', struct('CVPartition',cvp,...
    'MaxObjectiveEvaluations', 75, ...
    'AcquisitionFunctionName', 'expected-improvement-plus'));

% % Create the result struct with predict function
predictorExtractionFcn = @(t) t(:, predictorNames);
treePredictFcn = @(x) predict(classificationTree, x);
trainedClassifier.predictFcn = @(x) treePredictFcn(predictorExtractionFcn(x));

% Add additional fields to the result struct
trainedClassifier.ClassificationTree = classificationTree;